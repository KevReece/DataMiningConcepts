{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of BERT Strengths and Weaknesses\n",
    "\n",
    "This is a demonstration of Google's BERT LLM capabilities, in context of the capabilities of more recent models like Google's BARD/Gemini. The goal is simply to highlight a some key strengths and weaknesses of BERT in order inform it's useful applications. \n",
    "\n",
    "#### Context:\n",
    "- **BERT paper**: 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding': https://arxiv.org/abs/1810.04805\n",
    "- **Gemini report**: 'Gemini: A Family of Highly Capable Multimodal Models' Gemini Team: https://storage.googleapis.com/deepmind-media/gemini/gemini_1_report.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the pre-trained `bert-large-uncased` model, large variant. This model was trained on both the masked token and next sentence prediction tasks. There are many fine-tuned models built on this foundation, but we will focus on the core comprehension and knowledge capabilities of the model. \n",
    "\n",
    "Model documentation: https://huggingface.co/docs/transformers/v4.37.2/en/model_doc/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "bert_masked_model = BertForMaskedLM.from_pretrained('bert-large-uncased')\n",
    "bert_masked_model.eval()\n",
    "\n",
    "bert_sentence_model = BertForNextSentencePrediction.from_pretrained('bert-base-cased')\n",
    "bert_sentence_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Implementation\n",
    "\n",
    "### Mask Token Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_TEXT = bert_tokenizer.mask_token\n",
    "\n",
    "def print_mask_fill(text_with_single_mask, top_predictions_to_print=3, expected_word=None):\n",
    "    '''Prints the top predictions for a masked word with some text.\n",
    "    \n",
    "    `text_with_single_mask`: str, text with a single mask token.\n",
    "    `top_predictions_to_print`: int, number of top predictions to print.\n",
    "    `expected_word`: str, expected word to print the prediction of.'''\n",
    "\n",
    "    print(f\"Text with mask: {text_with_single_mask}\")\n",
    "    mask_token_index, mask_predictions = _predict_mask_fill(text_with_single_mask)\n",
    "    _print_top_predictions(top_predictions_to_print, mask_token_index, mask_predictions)\n",
    "    if expected_word:\n",
    "        _print_prediction_of_word(expected_word, mask_token_index, mask_predictions)\n",
    "\n",
    "def print_word_appropriateness(word_to_check, text, top_predictions_to_print=3):\n",
    "    '''Prints the given word's appropriateness in the given text.\n",
    "    \n",
    "    `word_to_check`: str, word from the text to have it's appropriateness checked.\n",
    "    `text`: str, text to check the word's appropriateness in.\n",
    "    `top_predictions_to_print`: int, number of top predictions to print.'''\n",
    "\n",
    "    print_mask_fill(text.replace(word_to_check, MASK_TEXT), top_predictions_to_print, word_to_check)\n",
    "\n",
    "def _predict_mask_fill(text_with_single_mask):\n",
    "    text_token_ids = bert_tokenizer.encode(text_with_single_mask, return_tensors='pt')\n",
    "    mask_token_index = torch.where(text_token_ids == bert_tokenizer.mask_token_id)[1]\n",
    "    with torch.no_grad():\n",
    "        model_output = bert_masked_model(text_token_ids)\n",
    "        mask_predictions = model_output[0]\n",
    "    return mask_token_index, mask_predictions\n",
    "\n",
    "def _print_top_predictions(top_predictions_to_print, mask_token_index, mask_predictions):\n",
    "    top_k_predictions = torch.topk(mask_predictions[0, mask_token_index][0], top_predictions_to_print)\n",
    "    for prediction_index, prediction_token_index in enumerate(top_k_predictions.indices):\n",
    "        predicted_token_word = bert_tokenizer.decode(prediction_token_index)\n",
    "        clean_predicted_token_word = predicted_token_word.replace(\" \", \"\")\n",
    "        predicted_probability = top_k_predictions.values[prediction_index]\n",
    "        print(f\"- Rank: {prediction_index+1}, Word: {clean_predicted_token_word}, Probability: {predicted_probability:.3f}\")\n",
    "        \n",
    "def _print_prediction_of_word(word, mask_token_index, mask_predictions):\n",
    "    word_index = bert_tokenizer.encode(word, return_tensors='pt')[0][1]\n",
    "    word_probability = mask_predictions[0, mask_token_index, word_index][0]\n",
    "    word_probability_rank = torch.sum(mask_predictions[0, mask_token_index] > word_probability) + 1\n",
    "    print(f\"- Rank: {word_probability_rank}, Word: {word}, Probability: {word_probability:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Similarity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_sentence_matches(query_sentence, sentences, top_predictions_to_print=3):\n",
    "    '''Prints the top matching sentences for a given query sentence.\n",
    "    \n",
    "    `query_sentence`: str, sentence to find the top matching sentences for.\n",
    "    `sentences`: list of str, sentences to match the query sentence against.\n",
    "    `top_predictions_to_print`: int, number of top predictions to print.'''\n",
    "    \n",
    "    similarities = []\n",
    "    for i in range(0, len(sentences)):\n",
    "        sentence_probabilities = _calculate_sentence_relationships(query_sentence, sentences[i])\n",
    "        similarity = sentence_probabilities[0][0]\n",
    "        similarities.append((sentences[i], similarity))\n",
    "    _print_top_matching_sentences(query_sentence, sentences, similarities, top_predictions_to_print)\n",
    "\n",
    "def _calculate_sentence_relationships(sentence_1, sentence_2):\n",
    "    sentences_encoding = bert_tokenizer.encode_plus(sentence_1, text_pair=sentence_2, return_tensors='pt')\n",
    "    sentence_relationship_logits = bert_sentence_model(**sentences_encoding)[0]\n",
    "    probabilities = softmax(sentence_relationship_logits, dim=1)\n",
    "    return probabilities\n",
    "\n",
    "def _print_top_matching_sentences(query_sentence, sentences_to_match, similarities, top_predictions_to_print):\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Top {top_predictions_to_print} matches for sentence: '{query_sentence}'\")\n",
    "    for i in range(0, min(top_predictions_to_print, len(sentences_to_match))):\n",
    "        print(f\"- Similarity: {similarities[i][1]:.4f} Sentence: '{similarities[i][0]}',\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Weaknesses\n",
    "\n",
    "### Numerical reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with mask: 10 + 10 = [MASK].\n",
      "- Rank: 1, Word: 10, Probability: 10.840\n",
      "- Rank: 2, Word: 0, Probability: 9.743\n",
      "- Rank: 3, Word: 1, Probability: 9.624\n",
      "- Rank: 14, Word: 20, Probability: 7.882\n"
     ]
    }
   ],
   "source": [
    "print_mask_fill(f\"10 + 10 = {MASK_TEXT}.\", expected_word=\"20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-word expression comprehension (Non-compositionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with mask: The gardener is [MASK] fingered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Rank: 1, Word: one, Probability: 8.942\n",
      "- Rank: 2, Word: two, Probability: 8.621\n",
      "- Rank: 3, Word: three, Probability: 8.307\n",
      "- Rank: 51, Word: green, Probability: 4.727\n"
     ]
    }
   ],
   "source": [
    "print_mask_fill(f\"The gardener is {MASK_TEXT} fingered.\", expected_word=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialog tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with mask: Alice: What's the weather like there? Bob: It's very cold. Is it the same for you? Alice: Not at all, it's [MASK] here.\n",
      "- Rank: 1, Word: different, Probability: 12.071\n",
      "- Rank: 2, Word: cooler, Probability: 10.281\n",
      "- Rank: 3, Word: warmer, Probability: 10.208\n",
      "- Rank: 12, Word: hot, Probability: 7.528\n",
      "Text with mask: The weather's not very cold, it's [MASK] here.\n",
      "- Rank: 1, Word: warm, Probability: 11.216\n",
      "- Rank: 2, Word: nice, Probability: 10.769\n",
      "- Rank: 3, Word: beautiful, Probability: 10.242\n",
      "- Rank: 4, Word: hot, Probability: 9.525\n"
     ]
    }
   ],
   "source": [
    "print_mask_fill(f\"Alice: What's the weather like there? Bob: It's very cold. Is it the same for you? Alice: Not at all, it's [MASK] here.\", expected_word=\"hot\")\n",
    "\n",
    "# Counter example without dialog:\n",
    "print_mask_fill(f\"The weather's not very cold, it's [MASK] here.\", expected_word=\"hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge breadth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with mask: The club in Berlin with a notoriously strict door policy is called [MASK].\n",
      "- Rank: 1, Word: club, Probability: 6.132\n",
      "- Rank: 2, Word: inferno, Probability: 5.731\n",
      "- Rank: 3, Word: astoria, Probability: 5.689\n",
      "- Rank: 1719, Word: Berghain, Probability: 1.094\n"
     ]
    }
   ],
   "source": [
    "print_mask_fill(f\"The club in Berlin with a notoriously strict door policy is called {MASK_TEXT}.\", expected_word=\"Berghain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Strengths\n",
    "\n",
    "Considering BERT's relative fast speed (versus other huge LLMs), and it's optimisation for sentence similarity and masked token prediction, it could still find application in a few contexts, as follows.\n",
    "\n",
    "### Fixing typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with mask: I [MASK] the product to be useful but overpriced.\n",
      "- Rank: 1, Word: found, Probability: 15.158\n",
      "- Rank: 2, Word: find, Probability: 13.372\n",
      "- Rank: 3, Word: consider, Probability: 12.052\n",
      "- Rank: 2564, Word: fund, Probability: 0.499\n"
     ]
    }
   ],
   "source": [
    "print_word_appropriateness(\"fund\", \"I fund the product to be useful but overpriced.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing OCR misreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text with mask: There will be additional costs if the above terms and conditions are [MASK] adhered to.\n",
      "- Rank: 1, Word: not, Probability: 18.069\n",
      "- Rank: 2, Word: strictly, Probability: 12.863\n",
      "- Rank: 3, Word: fully, Probability: 11.104\n",
      "- Rank: 7153, Word: hot, Probability: -1.586\n"
     ]
    }
   ],
   "source": [
    "print_word_appropriateness(\"hot\", \"There will be additional costs if the above terms and conditions are hot adhered to.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovering similar document titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 matches for sentence: 'Molecular structure of DNA fragments.'\n",
      "- Similarity: 1.0000 Sentence: 'Effectiveness of fragmented governments.',\n",
      "- Similarity: 0.9999 Sentence: 'Material strength of proteins.',\n",
      "- Similarity: 0.9978 Sentence: 'Genetics and climate.',\n"
     ]
    }
   ],
   "source": [
    "query_sentence = \"Molecular structure of DNA fragments.\"\n",
    "sentences = [\n",
    "    \"Class representation in ancient Egyptian names.\", \n",
    "    \"Methane propellant analysis for impact on marine life.\",\n",
    "    \"Genetics and climate.\",\n",
    "    \"Material strength of proteins.\",\n",
    "    \"Effectiveness of fragmented governments.\"]\n",
    "\n",
    "print_top_sentence_matches(query_sentence, sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discovering related sentences in a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 matches for sentence: 'How long is the warranty?'\n",
      "- Similarity: 1.0000 Sentence: 'The warranty length defaults as 3 years.',\n",
      "- Similarity: 1.0000 Sentence: 'There will be a reduction to 1 year in warranty length in the case of multiple users.The guarantee is voided if the product is used for commercial purposes.',\n",
      "- Similarity: 0.9994 Sentence: 'Keep children away from the wrapping.',\n"
     ]
    }
   ],
   "source": [
    "query_sentence = \"How long is the warranty?\"\n",
    "sentences = [\n",
    "    \"Size: 30cm x 10cm x 8 cm.\", \n",
    "    \"The warranty length defaults as 3 years.\",\n",
    "    \"Keep children away from the wrapping.\",\n",
    "    \"There will be a reduction to 1 year in warranty length in the case of multiple users.\"\n",
    "    \"The guarantee is voided if the product is used for commercial purposes.\",\n",
    "    \"Don't use the product in combination with other products.\"]\n",
    "\n",
    "print_top_sentence_matches(query_sentence, sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
